{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNywSgo4bpU2VhRMfCtxI+j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vina12alvina/Project6/blob/main/Project6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXaOpcXNmYRc",
        "outputId": "ceaa41be-1fc2-470c-c8dc-072cb5861547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hdfs\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting docopt (from hdfs)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from hdfs) (2.31.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from hdfs) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->hdfs) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->hdfs) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->hdfs) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->hdfs) (2024.2.2)\n",
            "Building wheels for collected packages: hdfs, docopt\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=340837be782ba6d59538c29e3c3ee6c650b5d76d4a680d36e72e602b1861e522\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=c4506710aacaa7aa1dbc22e1bfce1018136a67a04afe9547ac28541709eb088b\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built hdfs docopt\n",
            "Installing collected packages: docopt, hdfs\n",
            "Successfully installed docopt-0.6.2 hdfs-2.7.3\n"
          ]
        }
      ],
      "source": [
        "!pip install hdfs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install webhdfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9WRHMXEptTN",
        "outputId": "bd009d58-f65c-4461-9268-626435e8c958"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting webhdfs\n",
            "  Downloading WebHDFS-0.2.0.tar.gz (3.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: webhdfs\n",
            "  Building wheel for webhdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webhdfs: filename=WebHDFS-0.2.0-py3-none-any.whl size=4221 sha256=a4c0d8c387c7a6b69b63dfd768ad1e46ba67f370e53e9b225fa2355fd8041df0\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/87/83/728b1e25618dc228b4048aad8b7d69df18b33a0e97f3e06a57\n",
            "Successfully built webhdfs\n",
            "Installing collected packages: webhdfs\n",
            "Successfully installed webhdfs-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mrjob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtMrM-sfoqB9",
        "outputId": "1bf13f16-b061-4cda-d25f-9cbe1ba554bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mrjob\n",
            "  Downloading mrjob-0.7.4-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/439.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/439.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m430.1/439.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.6/439.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from mrjob) (6.0.1)\n",
            "Installing collected packages: mrjob\n",
            "Successfully installed mrjob-0.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the pywebhdfs module\n",
        "!pip install pywebhdfs\n",
        "\n",
        "from pywebhdfs.webhdfs import PyWebHdfsClient\n",
        "from pprint import pprint\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "filetime = datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "# Replace 'namenode_host' with the actual hostname or IP address of your Hadoop namenode\n",
        "namenode_host = 'namenode_host'  # Example: '192.168.1.100'\n",
        "\n",
        "my_file = '/digitalskola/project/dim_orders_vina.csv'\n",
        "hdfs = PyWebHdfsClient(host=namenode_host, port='50070', user_name='deddy')\n",
        "\n",
        "try:\n",
        "    data = hdfs.read_file(my_file)\n",
        "    data = data.decode().split('\\n')\n",
        "    data_list = [item.split(',') for item in data if item]\n",
        "\n",
        "    # Create a DataFrame and save to a CSV file\n",
        "    df = pd.DataFrame(data_list[1:], columns=data_list[0])\n",
        "    output_file = f'dim_orders_vina_{filetime}.csv'\n",
        "    df.to_csv(output_file, index=False)\n",
        "\n",
        "    print(f\"File saved as {output_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to read file from HDFS or save to CSV: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9cqdYbApPEW",
        "outputId": "c38efbec-8e55-4dd7-c91a-a299fb123516"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pywebhdfs in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pywebhdfs) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pywebhdfs) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pywebhdfs) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pywebhdfs) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pywebhdfs) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pywebhdfs) (2024.2.2)\n",
            "Failed to read file from HDFS or save to CSV: HTTPConnectionPool(host='namenode_host', port=50070): Max retries exceeded with url: /webhdfs/v1/digitalskola/project/dim_orders_vina.csv?op=OPEN&user.name=deddy (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x7bdc08c76080>: Failed to resolve 'namenode_host' ([Errno -2] Name or service not known)\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run mapreduce from file hadoop\n",
        "!python mapReduce.py output/dim_orders_vina_2024-05-11.csv > output/dim_orders_vina_2024-05-23.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koytTwJZy_on",
        "outputId": "219d0d50-862b-4eca-eccb-d6874aa6f200"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: output/dim_orders_vina_2024-05-23.txt: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r3sFfCFZMkPu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}